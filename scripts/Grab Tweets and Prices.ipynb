{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package vader_lexicon to\n",
      "[nltk_data]     C:\\Users\\brend\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package vader_lexicon is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\brend\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\brend\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import yfinance as yf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tweepy as tw\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "import emot\n",
    "import nltk # sentiment library\n",
    "from nltk.tokenize import TweetTokenizer\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import SnowballStemmer, WordNetLemmatizer\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "nltk.download('vader_lexicon') # download vader lexicon\n",
    "nltk.download(\"stopwords\")\n",
    "nltk.download(\"wordnet\")\n",
    "\n",
    "from nltk.sentiment import SentimentIntensityAnalyzer as SIA\n",
    "\n",
    "from textblob import TextBlob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n"
     ]
    }
   ],
   "source": [
    "#Grab cryptocurrency price\n",
    "\n",
    "btc_data = yf.download(tickers='BTC-USD', period='1mo', interval='1d')\n",
    "eth_data = yf.download(tickers='ETH-USD', period='1mo', interval='1d')\n",
    "\n",
    "btc_df = pd.DataFrame(btc_data)\n",
    "eth_df = pd.DataFrame(eth_data)\n",
    "\n",
    "btc_df.to_csv(\"btc_price.csv\")\n",
    "eth_df.to_csv(\"eth_price.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Grab tweets\n",
    "consumer_key= 'Ou9XaMR4qgy3KGr7cSfvhjnYl'\n",
    "consumer_secret= 'kTl5Vs6918QYgEkufJVPbpfbuyFAyyjYfkRcl2hAL5BjGyqxyj'\n",
    "access_token= '2991366318-LhMbjkJGvNkmO5bwSzVfMhZQWl19dzoPdgOWD8V'\n",
    "access_token_secret= 'qmRpWmw2UHP3VPYOoodeOIt2s8liaGnEaePDSF9JtFIYI'\n",
    "\n",
    "auth = tw.OAuthHandler(consumer_key, consumer_secret)\n",
    "auth.set_access_token(access_token, access_token_secret)\n",
    "api = tw.API(auth, wait_on_rate_limit=True)\n",
    "\n",
    "search_words = \"#btc OR #bitcoin OR bitcoin OR btc\"\n",
    "\n",
    "today = datetime.utcnow().date()- timedelta(days=1)\n",
    "\n",
    "yesterday = today - timedelta(days=1)\n",
    "\n",
    "date_since = datetime.today().strftime('%Y-%m-%d')\n",
    "\n",
    "tweets = tw.Cursor(api.search,\n",
    "              q=search_words,\n",
    "              lang=\"en\",\n",
    "              since=yesterday, until=today).items()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1385745298270552065 2021-04-23 23:59:59 MustafaRaaR [] https://twitter.com/MustafaRaaR/status/1385745298270552065 Also, the value of the coins can drop drastically in a single day. As much as 15%. httpsSkeptical, annoyed, undecided, uneasy or hesitant/t.co/tDf5suQLaughing, big grin or laugh with glassesX 0.005714285714285705\n",
      "1385745298127867904 2021-04-23 23:59:59 wokkrr [] https://twitter.com/wokkrr/status/1385745298127867904 RT @CryptoHunterGon: Perfect hold of 4H Pi line and daily 60 EMA for $woo \n",
      "\n",
      "Is it really this easy? \n",
      "\n",
      "BTC gonna have to hold current lows e… 0.32666666666666666\n",
      "1385745295758307328 2021-04-23 23:59:59 LinkFr0g [] https://twitter.com/LinkFr0g/status/1385745295758307328 @gross_bit What you fail to account for is LT sellers that may be rotating the money from BTC (selling) into alts (… httpsSkeptical, annoyed, undecided, uneasy or hesitant/t.co/SGP4RunUed -0.45\n",
      "1385745283577905153 2021-04-23 23:59:56 DaniySuniy ['BSV'] https://twitter.com/DaniySuniy/status/1385745283577905153 RT @iamZatoshi:  money bag  dragon  BITCOIN SV GIVEAWAY  dragon  money bag  \n",
      "\n",
      "I will give $50 in $BSV to 1 person in the morning. \n",
      "\n",
      "Like, Retweet &amp; Follow me. #BSV  rocket  httpsSkeptical, annoyed, undecided, uneasy or hesitant… -0.4\n",
      "1385745281661165580 2021-04-23 23:59:55 Cryptoplusrd ['SAFEMOON'] https://twitter.com/Cryptoplusrd/status/1385745281661165580 RT @safemoon: We are proud to announce we are now listed on @letsexchange_io Meaning you can now trade #SAFEMOON for any coin listed by Let… 0.8\n",
      "1385745279849222156 2021-04-23 23:59:55 CryptoWatchBot ['Investing', 'crypto', 'cash'] https://twitter.com/CryptoWatchBot/status/1385745279849222156 #Investing 51.2% in this optimal #crypto portfolio and 48.8% #cash in the past 24 hours would have given you a 4.9%… httpsSkeptical, annoyed, undecided, uneasy or hesitant/t.co/xCvIV8bpIZ -0.325\n"
     ]
    }
   ],
   "source": [
    "stop_words = stopwords.words(\"english\")\n",
    "stemmer = SnowballStemmer(\"english\", ignore_stopwords=True)\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "tokenzr = RegexpTokenizer('\\s+', gaps = True)\n",
    "    \n",
    "def stem_tokenize(text):\n",
    "    tokenized_text = tokenzr.tokenize(text.lower())\n",
    "    words = [lemmatizer.lemmatize(w) for w in tokenized_text if w not in stop_words]\n",
    "    stem_text = \" \".join([stemmer.stem(i) for i in words])\n",
    "\n",
    "    return stem_text #converted emoji to unicode description of emoji is return as string text\n",
    "\n",
    "\n",
    "def regex_tweet(tweet):\n",
    "    tweet = ' '.join(re.sub(\"(\\$[A-Za-z0-9]+)\", \" \", tweet).split())\n",
    "    tweet = ' '.join(re.sub(\"(@[A-Za-z0-9]+)|(#[A-Za-z0-9]+)\", \" \", tweet).split())\n",
    "    tweet = ' '.join(re.sub(\"(\\w+:\\/\\/\\S+)\", \" \", tweet).split())\n",
    "    tweet = ' '.join(re.sub(\"[\\.\\,\\!\\?\\:\\;\\-\\=]\", \" \", tweet).split())\n",
    "    tweet = ' '.join(re.sub(\"[\\[\\]]\", \" \", tweet).split())\n",
    "    return tweet\n",
    "\n",
    "\n",
    "def clean_mean(val):\n",
    "    return val.replace('_', ' ').replace('-', ' ').replace(':', ' ')\n",
    "\n",
    "\n",
    "def convert_emojicon(text):\n",
    "    for emoti in emot.emo_unicode.EMOTICONS:\n",
    "        if emoti in text:\n",
    "            text = text.replace(emoti, clean_mean(emot.emo_unicode.EMOTICONS.get(emoti, '')))\n",
    "            \n",
    "    for emoti in emot.emo_unicode.UNICODE_EMO:\n",
    "        if emoti in text:\n",
    "            text = text.replace(emoti, clean_mean(emot.emo_unicode.UNICODE_EMO.get(emoti, '')))\n",
    "            \n",
    "    for emoti in emot.emo_unicode.EMOTICONS_EMO:\n",
    "        if emoti in text:\n",
    "            text = text.replace(emoti, clean_mean(emot.emo_unicode.EMOTICONS_EMO.get(emoti, '')))\n",
    "            \n",
    "    return text\n",
    "\n",
    "sia = SIA()\n",
    "\n",
    "count = 0\n",
    "sentiment_counter = 0\n",
    "for tweet in tweets:\n",
    "    tweet_id = tweet.id\n",
    "    tweet_time = tweet.created_at\n",
    "    tweet_username = tweet.author.screen_name\n",
    "    \n",
    "    tweet_hashtags = tweet.entities['hashtags']\n",
    "    hashtags = []\n",
    "    for hashtag in tweet_hashtags:\n",
    "        hashtags.append(hashtag['text'])\n",
    "        \n",
    "    cashtags = \"\"\n",
    "    link = \"https://twitter.com/{username}/status/{id}\".format(username = tweet_username, id = tweet_id)\n",
    "    \n",
    "    tweet_text = tweet.text\n",
    "    tweet_text = convert_emojicon(tweet_text)\n",
    "    \n",
    "    tweet_sentiment = TextBlob(tweet_text).sentiment.polarity\n",
    "    sentiment_counter += tweet_sentiment\n",
    "        \n",
    "    print(tweet_id, tweet_time, tweet_username, hashtags, link, tweet_text, tweet_sentiment)\n",
    "    count += 1\n",
    "    if count > 5:\n",
    "        break\n",
    "    "
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
